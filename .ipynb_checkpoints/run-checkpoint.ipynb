{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !conda install --yes --prefix {sys.prefix} plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n# nom_convert_int \\n    update it in the software \\n    \\n# split time changes so please change it also\\n\\n\\n# update your code to take care of both csv and excel file  \\n    \\n    \\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun Jul 30 13:48:23 2017\n",
    "\n",
    "@author: Muddassar Sharif\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import cPickle as pickle\n",
    "from datetime import datetime\n",
    "import math\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import datetime\n",
    "#from multiple_files import *\n",
    "import io\n",
    "\n",
    "class preprocess():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.address= None\n",
    "        self.list_variables=[]\n",
    "        self.list_s_variables=[]\n",
    "        self.y_var=None\n",
    "        self.mean=[]\n",
    "        self.st_dev=[]\n",
    "        self.io_dim=[[],[]]\n",
    "        self.data_array=[]\n",
    "        \n",
    "        self.data= 0  \n",
    "        self.y=None\n",
    "        self.key={}\n",
    "        self.convert=False\n",
    "        self.train_x=[]\n",
    "        self.train_x=[]\n",
    "        self.train_y=[]\n",
    "        self.test_y=[]\n",
    "        self.pre_x=[]\n",
    "        self.pre_y=[]\n",
    "        self.time= None\n",
    "        \n",
    "        \n",
    "        \n",
    "    def file_address(self, address):\n",
    "        self.address= address\n",
    "        \n",
    "        \n",
    "    def save_data_and_y(self):\n",
    "        basename = \"preprocessing/preprocessing\"\n",
    "        suffix = datetime.datetime.now().strftime(\"%y%m%d_%H%M%S\")\n",
    "        file_name = \"_\".join([basename, suffix]) + \".pickle\"  # e.g. 'mylogfile_120508_171442'\n",
    "        self.preprocess_p_file = file_name \n",
    "        self.data_array.append(self.preprocess_p_file)\n",
    "        \n",
    "        with open(self.data_array[-1], 'wb') as f:\n",
    "            pickle.dump((self.data, self.y), f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "            \n",
    "        # time to empty the spaces \n",
    "        self.data=0\n",
    "        self.y= None\n",
    "        self.train_x=[]\n",
    "        self.train_x=[]\n",
    "        self.train_y=[]\n",
    "        self.test_y =[]\n",
    "        \n",
    "            \n",
    "    def load_data_and_y(self, i):\n",
    "        with open(self.data_array[i], 'rb') as f:\n",
    "            self.data, self.y= pickle.load(f)\n",
    "\n",
    "        \n",
    "        \n",
    "    def read_file(self, nrows, start):   # needs modification\n",
    "        try:\n",
    "            if start== 0:\n",
    "                \n",
    "                if nrows== None:\n",
    "\n",
    "\n",
    "                    try:\n",
    "                        self.data= pd.read_csv(self.address)\n",
    "                    except:\n",
    "                        self.data = pd.read_excel(self.address)\n",
    "\n",
    "                    return len(self.data.index)\n",
    "                else:\n",
    "                    self.data= pd.read_csv(self.address, nrows= nrows)\n",
    "                    return len(self.data.index)\n",
    "            else:\n",
    "                self.data= pd.read_csv(self.address)\n",
    "                index= len(self.data.index)\n",
    "                self.data = self.data[start:]\n",
    "                return index\n",
    "                \n",
    "        except:\n",
    "            print(\"File does not exist\")\n",
    "            return 0\n",
    "    \n",
    "    def pandas_data(self):\n",
    "        return self.data\n",
    "          \n",
    "    def variables(self):\n",
    "        self.list_variables= self.data.columns.values.tolist()\n",
    "        self.list_s_variables= self.list_s_variables\n",
    "        return self.list_variables\n",
    "            \n",
    "    def extract_variables(self, variables):\n",
    "        if variables == None:\n",
    "            if self.list_s_variables==[]:\n",
    "                \n",
    "                self.list_s_variables= np.array(self.list_variables)\n",
    "        else:\n",
    "            self.list_s_variables= np.array(variables)\n",
    "        \n",
    "        if self.convert== True:\n",
    "            self.data=self.data[np.append(self.list_s_variables, self.y_var)]\n",
    "        return self.list_s_variables\n",
    "    \n",
    "    def replace_nan(self, nan):\n",
    "        try:\n",
    "            \n",
    "            self.data= self.data.fillna(nan)\n",
    "            return \" replace nan done!\"\n",
    "        except:\n",
    "            print(\"sorry an error occured!\" )\n",
    "            return \" Sorry replace nan not done\"\n",
    "        \n",
    "    \n",
    "    def split_time(self):\n",
    "        self.time= None\n",
    "        temp=[]\n",
    "        for col in self.list_s_variables: \n",
    "            if self.data[col].dtype == 'object':\n",
    "                try:\n",
    "                    temp2 = pd.to_datetime(self.data[col][:10])\n",
    "                    temp.append(col)\n",
    "                except ValueError:\n",
    "                    pass\n",
    "        \n",
    "        if temp== []:\n",
    "            return \"files does not have the time attribute\"\n",
    "        else:\n",
    "            self.time= temp[0]\n",
    "            temp= pd.to_datetime(self.data[self.time])\n",
    "            \n",
    "             \n",
    "     \n",
    "            self.data[self.time+ 'yearrr']= temp.dt.year\n",
    "            self.data[self.time+ 'monthhh']= temp.dt.month\n",
    "            self.data[self.time + 'dayyy']= temp.dt.day\n",
    "            if self.convert== False:  # limit to running only the first time\n",
    "            \n",
    "                self.list_s_variables= np.append(self.list_s_variables, self.time+ 'yearrr')\n",
    "                self.list_s_variables= np.append(self.list_s_variables, self.time+ 'monthhh')\n",
    "                self.list_s_variables= np.append(self.list_s_variables, self.time+ 'dayyy')\n",
    "                self.list_variables= np.append(self.list_variables, self.time+ 'yearrr')\n",
    "                self.list_variables= np.append(self.list_variables, self.time+ 'monthhh')\n",
    "                self.list_variables= np.append(self.list_variables, self.time+ 'dayyy')\n",
    "                \n",
    "                i= np.where(self.list_s_variables==self.time)\n",
    "                self.list_s_variables= np.delete(self.list_s_variables, i[0][0], None)\n",
    "                \n",
    "    \n",
    "            self.data=self.data.drop(self.time, axis=1)\n",
    "            \n",
    "    \n",
    "            return \"removed and splitted \" +self.time +\"!\"\n",
    "    \n",
    "    \n",
    "    def delete_row(self,row):\n",
    "        try:\n",
    "            self.data=self.data.drop(row, axis=1) \n",
    "            i= np.where(self.list_s_variables==row)\n",
    "            self.list_s_variables= np.delete(self.list_s_variables, i[0][0], None)\n",
    "            return \"row \" +str(row) +\" deleted\"\n",
    "        except:\n",
    "            return \"row \" +str(row) + \" does not exist\"\n",
    "        \n",
    "    def Filterout(self, row, value):\n",
    "        try:\n",
    "            self.data = self.data.loc[self.data[row]!=value]\n",
    "            return \"data only contain rows with: \" + str(row) +\" != \" + str(value)\n",
    "        except:\n",
    "            return \"please check your inputs please. Filteration not done\"\n",
    "        \n",
    "    def Filterout_product2(self, row, value,row2,value2, y):\n",
    "        try:\n",
    "            self.pre_x = self.data.loc[self.data[row]==value]\n",
    "            self.pre_x= self.pre_x.loc[self.data[row2]==value2]\n",
    "            self.data = self.data.loc[self.data[row]!=value]\n",
    "\n",
    "            self.pre_y= np.array(self.pre_x[y])\n",
    "        \n",
    "            self.pre_x=self.pre_x.drop(y, axis=1)\n",
    "            return \"data for prediction containing rows with: \" + str(row) +\" != \" + str(value)\n",
    "        except:\n",
    "            return \"please check your inputs please. Filteration of new product data not done\"\n",
    "    def Filterout_product(self, row, value, y):\n",
    "        try:\n",
    "            self.pre_x = self.data.loc[self.data[row]==value]\n",
    "            self.data = self.data.loc[self.data[row]!=value]\n",
    "\n",
    "            self.pre_y= np.array(self.pre_x[y])\n",
    "        \n",
    "            self.pre_x=self.pre_x.drop(y, axis=1)\n",
    "            return \"data for prediction containing rows with: \" + str(row) +\" != \" + str(value)\n",
    "        except:\n",
    "            return \"please check your inputs please. Filteration of new product data not done\"\n",
    "        \n",
    "        \n",
    "        \n",
    "    def Filterin(self, row, value):\n",
    "        try:\n",
    "            self.data = self.data.loc[self.data[row]==value]\n",
    "            return \"data only contain rows with: \" + str(row) +\"==\" + str(value)\n",
    "        except:\n",
    "            return \"please check your inputs please. Filteration not done\"\n",
    "        \n",
    "    def Binning(self, inp):# not tested yet\n",
    "        try:\n",
    "            \n",
    "            if inp==None:\n",
    "                for x in self.list_s_variables:\n",
    "                    if (type(self.data[x][1])== np.int64 ) or (type(self.data[x][1])== np.float64 ):\n",
    "        #                    #binning when required\n",
    "                            if (self.data[[x]].max()-self.data[[x]].min()) > 40:\n",
    "                                length= 20\n",
    "                                group_names = [i for i in range(1,length+1)]\n",
    "                                jump= (self.data[[x]].max()-self.data[[x]].min())/length+ (self.data[[x]].max()-self.data[[x]].min())%length\n",
    "                                number=self.data[[x]].min()                \n",
    "                                bins=[]\n",
    "                                for j in range(len(length)+1):              \n",
    "                                    bins.append(number)\n",
    "                                    number= number+jump\n",
    "                                \n",
    "                                bins[0]= bins[0]-10\n",
    "                                bins[-1]= bins[-1] + 10\n",
    "                                self.data[x] = pd.cut(self.data[x], bins, labels=group_names)\n",
    "                    else:\n",
    "                        pass\n",
    "            \n",
    "            else:\n",
    "                if (self.data[[inp]].max()-self.data[[inp]].min()) > 40:\n",
    "                    length= 20\n",
    "                    group_names = [i for i in range(1,length+1)]\n",
    "                    jump= (self.data[[x]].max()-self.data[[x]].min())/length+ (self.data[[x]].max()-self.data[[x]].min())%length\n",
    "                    number=self.data[[x]].min()                \n",
    "                    bins=[]\n",
    "                    for j in range(len(length)+1):              \n",
    "                        bins.append(number)\n",
    "                        number= number+jump\n",
    "                                \n",
    "                        bins[0]= bins[0]-10\n",
    "                        bins[-1]= bins[-1] + 10\n",
    "                        self.data[x] = pd.cut(self.data[x], bins, labels=group_names)\n",
    "            return \"Binning Done!\"\n",
    "        except:\n",
    "            return \"An error occured when Binning\"\n",
    "        \n",
    "        \n",
    "    def category_to_nominal(self):\n",
    "        if self.convert==False:\n",
    "            self.convert= self.make_key()\n",
    "        \n",
    "        for x in self.list_s_variables:\n",
    "\n",
    "            if (type(np.array(self.data[x])[1])== np.int64 ) or (type(np.array(self.data[x])[1])== np.float64 ) or (type(np.array(self.data[x])[1])== long ):\n",
    "#                    std= self.data[[x]].std()\n",
    "#                    mean= self.data[[x]].mean()\n",
    "#                    self.data[[x]]=np.tan(np.array(((self.data[[x]]-mean)/std)*.01 +1))\n",
    "                pass\n",
    "            else:\n",
    "                self.data[[x]]=self.nom_convert_int(self.data[[x]],x)\n",
    "              \n",
    "        return \"categoricol to nominal done!\"\n",
    "            \n",
    "    def y_to_float(self, y):\n",
    "        try:\n",
    "            self.data[y]= np.array(self.data[y].str.replace(\",\", \"\").astype(float))\n",
    "            return \" y converted to float \"\n",
    "        \n",
    "        except:\n",
    "            return \" Error while converting y to float\"\n",
    "        \n",
    "        \n",
    "    def choose_y(self, y):\n",
    "        temp= self.y_to_float(y)\n",
    "        self.y_var= y\n",
    "        self.y= np.array(self.data[y])\n",
    "        \n",
    "        self.data=self.data.drop(y, axis=1)\n",
    "        \n",
    "        if self.convert== False:\n",
    "            i= np.where(self.list_s_variables==y)\n",
    "    \n",
    "            self.list_s_variables= np.delete(self.list_s_variables, i[0][0], None)\n",
    "        \n",
    "        return \"y choosen\"\n",
    "    \n",
    "    def normalize(self):\n",
    "#        self.mean\n",
    "#        self.st_dev\n",
    "        return True\n",
    "\n",
    "    \n",
    "    def calculate_dim(self):\n",
    "        for x in self.list_s_variables:\n",
    "            temp=(int(max(len(self.data[x].unique()), self.data[x].max()))+5)\n",
    "            self.io_dim[0].append(temp)\n",
    "            if temp>= 8:   \n",
    "                self.io_dim[1].append(int(temp*.025+3))\n",
    "            else:\n",
    "                self.io_dim[1].append(temp-1)\n",
    "                \n",
    "        return \"dimensions calculated\"\n",
    "        \n",
    "    def test_train_divide(self, l):\n",
    "        self.train_x , self.test_x, self.train_y ,self.test_y= train_test_split(np.array(self.data),np.array(self.y), test_size=l)\n",
    "    \n",
    "    \n",
    "    def get_train_x(self):\n",
    "        return self.train_x\n",
    "    def get_test_x(self):\n",
    "        return self.test_x        \n",
    "    def get_train_y(self):\n",
    "        return self.train_y  \n",
    "    def get_test_y(self):\n",
    "        return self.test_y\n",
    "      \n",
    "    def get_x(self):\n",
    "        return self.data\n",
    "    \n",
    "    def get_y(self):\n",
    "        return self.y\n",
    "    \n",
    "    def get_pre_x(self):\n",
    "        return self.pre_x\n",
    "    \n",
    "    def get_pre_y(self):\n",
    "        return self.pre_y \n",
    "        \n",
    "    \n",
    "    def get_y_var(self):\n",
    "        return self.y_var\n",
    "    \n",
    "    def get_dim(self):\n",
    "        return self.io_dim\n",
    "    \n",
    "    def get_key(self):\n",
    "        return self.key\n",
    "    \n",
    "    def get_s_variables(self):\n",
    "        return self.list_s_variables\n",
    "    \n",
    "    def get_time_var_name(self):\n",
    "        return self.time\n",
    "    \n",
    "    def set_key(self, key):\n",
    "        self.key= key\n",
    "        self.convert=True\n",
    "\n",
    "    \n",
    "    def preprocess_data(self):\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def split_data(self, split_rate):\n",
    "        return True\n",
    "        #store split data somewhere\n",
    "     \n",
    "    def save_file(self, path):\n",
    "        self.data.to_pickle(path, compression='infer')\n",
    "        return path\n",
    "        #mongodb vs pickle for now\n",
    "        # how about saving pickle file in mongodb\n",
    "        \n",
    "        \n",
    "    def nom_convert_int(self,df,x):     \n",
    "        import numpy as np\n",
    "        counter=0\n",
    "        x_c= np.array(df)\n",
    "        dic=self.key[x]\n",
    "        for i in range(len(x_c)):\n",
    "            \n",
    "            try:\n",
    "                x_c[i][0]= int(x_c[i][0])\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            if x_c[i][0] in dic:\n",
    "                pass\n",
    "            else:\n",
    "                dic[x_c[i][0]]=counter\n",
    "                counter=counter+1\n",
    "        for j in range(len(x_c)):\n",
    "             x_c[j][0]=dic[x_c[j][0]]\n",
    "        \n",
    "        self.key[x]=dic\n",
    "        return x_c\n",
    "    \n",
    "    \n",
    "    def make_key(self):\n",
    "        for i in self.list_s_variables:\n",
    "            self.key[i]={}\n",
    "            \n",
    "        self.convert= True\n",
    "        return True\n",
    "    \n",
    "    \n",
    "    def get_key_for_perdiction(self):\n",
    "        \n",
    "        return [self.list_s_variables, self.key]\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# nom_convert_int \n",
    "    update it in the software \n",
    "    \n",
    "# split time changes so please change it also\n",
    "\n",
    "\n",
    "# update your code to take care of both csv and excel file  \n",
    "    \n",
    "    \n",
    "\"\"\"    \n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from models import *\n",
    "from graph import *\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.setrecursionlimit(10000)\n",
    "import datetime\n",
    "import json\n",
    "import dill\n",
    "import plotly\n",
    "from plotly import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "class Dashboard():\n",
    "\n",
    "    def __init__(self, address, y_var, t,m, t2,m2):\n",
    "        self.data_address= address\n",
    "        self.t=t\n",
    "        self.m=m\n",
    "        self.t2=t2\n",
    "        self.m2=m2\n",
    "#        self.models={'LinearModel':[LinearModel() for i in range(3)],'RF':[RF() for i in range(3)], 'SVM': [SVM() for i in range(3)], 'XGBoost':[XGBoost() for i in range(3)], 'HistricalMedian':[HistricalMedian() for i in range(3)], 'KNN':[KNN() for i in range(3)], 'NN_with_EntityEmbedding': [NN_with_EntityEmbedding() for i in range(3)], 'NN2_with_EntityEmbedding': [NN2_with_EntityEmbedding() for i in range(3)], 'NN': [NN() for i in range(3)] }\n",
    "        self.models={'NN_with_EntityEmbedding': [NN_with_EntityEmbedding() for i in range(3)]}\n",
    "  #      self.models={'NN_with_EntityEmbedding': [NN_with_EntityEmbedding() for i in range(3)], 'Xgboost': [XGBoost() for i in range(3)]}\n",
    "#   'NN_with_EntityEmbedding': [NN_with_EntityEmbedding() for i in range(3)], 'xboost': [XGBoost() for i in range(3)]\n",
    "        self.best_model={}\n",
    "        self.y_variable=y_var\n",
    "        basename = \"preprocessing/preprocessing_object\"\n",
    "        suffix = datetime.datetime.now().strftime(\"%y%m%d_%H%M%S\")\n",
    "        file_name = \"_\".join([basename, suffix]) + \".pickle\"  # e.g. 'mylogfile_120508_171442'\n",
    "        self.preprocess_p_file = file_name\n",
    "        suffix = datetime.datetime.now().strftime(\"%y%m%d_%H%M%S\")\n",
    "        file_name = \"_\".join(['bestmodel/best_model', suffix]) + \".yaml\"  # e.g. 'mylogfile_120508_171442'\n",
    "        self.best_model_file= file_name\n",
    "        self.preprocess_object= preprocess()\n",
    "        self.x=None\n",
    "        self.preprocess_object.file_address(address)\n",
    "        self.mode= \"train\"\n",
    "        self.rows_info= {\"start\":0, \"end\":0}\n",
    "        self.graph_objects=[]\n",
    "        self.key= None\n",
    "        \n",
    "        \n",
    "    #save and load preprocess object \n",
    "    def save_preprocess_object(self):\n",
    "        with open(self.preprocess_p_file, 'wb') as f:\n",
    "            pickle.dump((self.preprocess_object), f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            \n",
    "    def load_preprocess_object(self):\n",
    "        with open(self.preprocess_p_file, 'rb') as f:\n",
    "            self.preprocess_object= pickle.load(f)\n",
    "            \n",
    "            \n",
    "    def check_for_new_data(self):\n",
    "        \n",
    "#        try:\n",
    "            if len(pd.read_csv(self.data_address).index)== self.rows_info[\"end\"]:\n",
    "                print(\"No New Data added to the file\")\n",
    "            \n",
    "            else:\n",
    "            # time to train this baby : incremental learning \n",
    "                print(len(pd.read_csv(self.data_address).index), self.rows_info[\"end\"])\n",
    "                print(\"file has new data\")\n",
    "                self.new_data_transformation()\n",
    "#        except:\n",
    "#            print(\"some error with the file so retraining can not be done\")\n",
    "\n",
    "    \n",
    "    def test_train_switch(self, mde):\n",
    "        self.mode= mde\n",
    "        \n",
    "    def more_data(self, address):\n",
    "        self.data_address.append(address)\n",
    "        \n",
    "    def file_transformation(self):\n",
    "        \n",
    "        print(\"reading file\")\n",
    "\n",
    "        temp= self.preprocess_object.read_file(None, self.rows_info[\"start\"])  # just reading 10000 rows for testing right now\n",
    "        self.rows_info[\"end\"]= temp\n",
    "      \n",
    "        var= self.preprocess_object.variables()\n",
    "        print(var)\n",
    "\n",
    "        sel_var= self.preprocess_object.extract_variables(None)\n",
    "        print(sel_var) \n",
    "        \n",
    "        ans= self.preprocess_object.replace_nan(0)\n",
    "        print(ans)\n",
    "        \n",
    "        ans= self.preprocess_object.split_time()  # automate this process finding the data using\n",
    "        print(ans) \n",
    "    \n",
    "        ans= self.preprocess_object.Filterout_product2(self.t,self.m, self.t2, self.m2, self.y_variable)\n",
    "        print(ans)\n",
    "        \n",
    "        if self.mode == \"train\":  \n",
    "            ans= self.preprocess_object.Filterout(self.y_variable, 0)\n",
    "            ans= self.preprocess_object.choose_y(self.y_variable)\n",
    "\n",
    "            print(ans)\n",
    "            \n",
    "#         ans= self.preprocess_object.Filterout_product(\"STYLE #\",'Style #1', self.y_variable)\n",
    "#         print(ans)        \n",
    "            \n",
    "      \n",
    "        ans1= self.preprocess_object.category_to_nominal()\n",
    "        print(ans1)\n",
    "        dim= self.preprocess_object.calculate_dim()\n",
    "        print(dim)\n",
    "#         value= self.preprocess_object.get_key()['STYLE #']['Style #3']\n",
    "#         print(value)\n",
    "        \n",
    "#         ans= self.preprocess_object.Filterout_product(\"STYLE #\",value, self.y_variable)\n",
    "#         print(ans)\n",
    "\n",
    "#         if self.mode == \"train\":  \n",
    "#             ans= self.preprocess_object.Filterout(self.y_variable, 0)\n",
    "#             ans= self.preprocess_object.choose_y(self.y_variable)\n",
    "#             print(ans)\n",
    "\n",
    "        \n",
    "        self.preprocess_object.test_train_divide(.05)\n",
    "        self.x= self.preprocess_object.get_test_x()\n",
    "        \n",
    "\n",
    "        \n",
    "    # function to take care of training when new data comes in\n",
    "    def new_data_transformation(self):\n",
    "        \n",
    "        self.save_preprocess_object()\n",
    "        print(\"reading file\")\n",
    "        self.preprocess_object.save_data_and_y()    # this will backup previous data and y\n",
    "        temp= self.preprocess_object.read_file(None, self.rows_info[\"end\"])    # reading new data\n",
    "        \n",
    "        \n",
    "        \n",
    "        ans= self.preprocess_object.split_time()  # time variable taken care of changed from self.preprocess_object.get_time_var_name()\n",
    "        print(ans) \n",
    "\n",
    "        sel_var= self.preprocess_object.extract_variables(self.preprocess_object.get_s_variables())  # this will give an errot right now\n",
    "        print(sel_var) \n",
    "        \n",
    "        ans= self.preprocess_object.replace_nan(0)\n",
    "        print(ans)\n",
    "        \n",
    "\n",
    "        \n",
    "        if self.mode == \"train\":  \n",
    "            ans= self.preprocess_object.Filterout(self.y_variable, 0)\n",
    "            ans= self.preprocess_object.choose_y(self.y_variable)\n",
    "\n",
    "            print(ans)\n",
    "            \n",
    "            # preprocess function to divide the time between test and train\n",
    "            \n",
    "      \n",
    "        ans1= self.preprocess_object.category_to_nominal()                               # checked for errors and is working properly.\n",
    "        print(ans1)\n",
    "\n",
    "        self.preprocess_object.test_train_divide(.01)                                    # no need for this step as we are just training\n",
    "        self.save_preprocess_object()\n",
    "        self.train_best_model()\n",
    "        \n",
    "        self.rows_info[\"end\"] = temp\n",
    "        \n",
    "\n",
    "    def train_best_model(self):\n",
    "        for model_name in self.best_model.keys():\n",
    "                self.best_model[model_name][0].train()    # make a traiining function to just train the file\n",
    "        \n",
    "    \n",
    "\n",
    "   \n",
    "    def finding_best_model(self):\n",
    "        self.save_preprocess_object()\n",
    "        if self.best_model.keys()!=[]:\n",
    "            for model in self.best_model.keys():\n",
    "                print('fitting'+ str(model))\n",
    "                for i in range(len(self.best_model[model])):\n",
    "                    self.best_model[model][i].input(self.preprocess_object)\n",
    "        \n",
    "        else:\n",
    "            for model in self.models.keys():\n",
    "                for i in range(len(self.models[model])):\n",
    "                    print('fitting'+ str(model))\n",
    "                    self.models[model][i].input(self.preprocess_object)\n",
    "                    \n",
    "            self.update_best_model()\n",
    "\n",
    "\n",
    "    def update_best_model(self):\n",
    "        temp= [None,None, 1000000000000000000000000000000]\n",
    "        for i in self.models.keys():\n",
    "            for model in self.models[i]:\n",
    "                if model.get_results()<temp[2]:\n",
    "                    temp=[i, model, model.get_results]\n",
    "        self.best_model[temp[0]]=[temp[1]]\n",
    "        self.preprocess_object.save_data_and_y()\n",
    "        #self.save_preprocess_object()        \n",
    "        #self.preprocess_object= None   # now added to reduce the burden on the code\n",
    "\n",
    "    def get_prediction_key(self):\n",
    "        #self.load_preprocess_object()\n",
    "        self.key= self.preprocess_object.get_key_for_perdiction()\n",
    "        return [-1, self.key[0], self.key[1]]\n",
    "#        graph1= graph()\n",
    "#        self.graph_objects.append(graph1) \n",
    "#        self.graph_objects[-1].key_from_user(key)\n",
    "#        return [self.graph_objects.index(self.graph_objects[-1]), key[0], key[1]]\n",
    "    \n",
    "    \n",
    "    \n",
    "    def make_graph_object(self):\n",
    "#        self.load_preprocess_object()\n",
    "#        key= self.preprocess_object.get_key_for_perdiction()\n",
    "        graph1= graph()\n",
    "        self.graph_objects.append(graph1) \n",
    "        self.graph_objects[-1].key_from_user(self.key)\n",
    "        return [self.graph_objects.index(self.graph_objects[-1])]\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "    def make_graph(self,k, user_in):\n",
    "        if user_in != None:\n",
    "            \n",
    "            self.graph_objects[k].user_input(user_in)\n",
    "       # return self.graph_objects[k].get_df_for_per()\n",
    "        y= self.best_model[self.best_model.keys()[0]][0].guess(np.array(self.graph_objects[k].get_df_for_per()))  \n",
    "        self.graph_objects[k].set_per_y(y)\n",
    "        return [self.graph_objects.index(self.graph_objects[k]), self.graph_objects[k].get_plot_data()]\n",
    "\n",
    "\n",
    "\n",
    "    def get_best_model(self):\n",
    "        return self.best_model\n",
    "    \n",
    "    def get_trained_models(self):\n",
    "        return self.models\n",
    "    \n",
    "    def get_preporcessed_file(self):\n",
    "        return self.preprocess_object\n",
    "\n",
    "    def save(self):\n",
    "        #save the best model\n",
    "        #s= json.dumps(self.best_model)\n",
    "\n",
    "        y = self.best_model[self.best_model.keys()[0]][0].guess(self.preprocess_object.get_test_x())\n",
    "        print(y)\n",
    "\n",
    "        plotly.tools.set_credentials_file(username='ms8909', api_key='OOQ413hzFuXQFdeEbpJK')\n",
    "\n",
    "        x_temp = []\n",
    "        for i in range(len(y)):\n",
    "            x_temp.append(i)\n",
    "        data = []\n",
    "        trace1 = go.Scatter(\n",
    "            x=x_temp,\n",
    "            y=y,\n",
    "            mode='lines',\n",
    "            name='predicted Sales'\n",
    "        )\n",
    "        data.append(trace1)\n",
    "\n",
    "        trace2 = go.Scatter(\n",
    "            x=x_temp,\n",
    "            y=self.preprocess_object.get_test_y(),\n",
    "            mode='lines',\n",
    "            name='actual'\n",
    "        )\n",
    "\n",
    "        data.append(trace2)\n",
    "\n",
    "        fig = dict(data=data)\n",
    "        py.iplot(fig, filename='line-mode')\n",
    "        with open(self.best_model_file, 'w') as f:\n",
    "            dill.dump(self.best_model, f)\n",
    "            #pickle.dump((self.best_model), f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            \n",
    "        return self.best_model[self.best_model.keys()[0]][0].get_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "please specify file_name and the predicting variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_object= Dashboard('Aaron_Data.csv', 'UnitsShipped', \"STYLE #\",'Style #1', 'Season','17SU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading file\n",
      "['Division', 'Season', 'Product Type', 'Customer Type Description', 'Customer #', 'Label (Style Mst)', 'Label Desc. (Order Detail)', 'Category Description', 'STYLE #', 'UnitsShipped', 'Order Type Desc', 'Date Start']\n",
      "['Division' 'Season' 'Product Type' 'Customer Type Description'\n",
      " 'Customer #' 'Label (Style Mst)' 'Label Desc. (Order Detail)'\n",
      " 'Category Description' 'STYLE #' 'UnitsShipped' 'Order Type Desc'\n",
      " 'Date Start']\n",
      " replace nan done!\n",
      "removed and splitted Date Start!\n",
      "data for prediction containing rows with: STYLE # != Style #1\n",
      "y choosen\n",
      "categoricol to nominal done!\n",
      "dimensions calculated\n"
     ]
    }
   ],
   "source": [
    "file_object.file_transformation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fittingNN_with_EntityEmbedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "models.py:470: UserWarning:\n",
      "\n",
      "The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "\n",
      "models.py:471: UserWarning:\n",
      "\n",
      "Update your `Dense` call to the Keras 2 API: `Dense(3000, kernel_initializer=\"uniform\")`\n",
      "\n",
      "models.py:474: UserWarning:\n",
      "\n",
      "Update your `Dense` call to the Keras 2 API: `Dense(1000, kernel_initializer=\"uniform\")`\n",
      "\n",
      "models.py:477: UserWarning:\n",
      "\n",
      "Update your `Dense` call to the Keras 2 API: `Dense(200, kernel_initializer=\"uniform\")`\n",
      "\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/keras/models.py:939: UserWarning:\n",
      "\n",
      "The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 143697 samples, validate on 7563 samples\n",
      "Epoch 1/20\n",
      "143488/143697 [============================>.] - ETA: 0s - loss: 0.0099Epoch 00001: val_loss improved from inf to 0.00760, saving model to saved_models/best_model_weights.hdf5\n",
      "143697/143697 [==============================] - 20s 140us/step - loss: 0.0099 - val_loss: 0.0076\n",
      "Epoch 2/20\n",
      "143488/143697 [============================>.] - ETA: 0s - loss: 0.0073Epoch 00002: val_loss improved from 0.00760 to 0.00720, saving model to saved_models/best_model_weights.hdf5\n",
      "143697/143697 [==============================] - 17s 121us/step - loss: 0.0073 - val_loss: 0.0072\n",
      "Epoch 3/20\n",
      "143488/143697 [============================>.] - ETA: 0s - loss: 0.0064Epoch 00003: val_loss improved from 0.00720 to 0.00654, saving model to saved_models/best_model_weights.hdf5\n",
      "143697/143697 [==============================] - 17s 120us/step - loss: 0.0064 - val_loss: 0.0065\n",
      "Epoch 4/20\n",
      "143360/143697 [============================>.] - ETA: 0s - loss: 0.0057Epoch 00004: val_loss improved from 0.00654 to 0.00639, saving model to saved_models/best_model_weights.hdf5\n",
      "143697/143697 [==============================] - 17s 121us/step - loss: 0.0057 - val_loss: 0.0064\n",
      "Epoch 5/20\n",
      "143488/143697 [============================>.] - ETA: 0s - loss: 0.0052Epoch 00005: val_loss improved from 0.00639 to 0.00626, saving model to saved_models/best_model_weights.hdf5\n",
      "143697/143697 [==============================] - 17s 120us/step - loss: 0.0052 - val_loss: 0.0063\n",
      "Epoch 6/20\n",
      "143360/143697 [============================>.] - ETA: 0s - loss: 0.0048Epoch 00006: val_loss improved from 0.00626 to 0.00620, saving model to saved_models/best_model_weights.hdf5\n",
      "143697/143697 [==============================] - 17s 120us/step - loss: 0.0048 - val_loss: 0.0062\n",
      "Epoch 7/20\n",
      "143360/143697 [============================>.] - ETA: 0s - loss: 0.0045Epoch 00007: val_loss improved from 0.00620 to 0.00615, saving model to saved_models/best_model_weights.hdf5\n",
      "143697/143697 [==============================] - 17s 120us/step - loss: 0.0045 - val_loss: 0.0061\n",
      "Epoch 8/20\n",
      "143488/143697 [============================>.] - ETA: 0s - loss: 0.0042Epoch 00008: val_loss did not improve\n",
      "143697/143697 [==============================] - 17s 119us/step - loss: 0.0042 - val_loss: 0.0063\n",
      "Epoch 9/20\n",
      "143488/143697 [============================>.] - ETA: 0s - loss: 0.0040Epoch 00009: val_loss improved from 0.00615 to 0.00614, saving model to saved_models/best_model_weights.hdf5\n",
      "143697/143697 [==============================] - 17s 120us/step - loss: 0.0040 - val_loss: 0.0061\n",
      "Epoch 10/20\n",
      "143232/143697 [============================>.] - ETA: 0s - loss: 0.0038Epoch 00010: val_loss improved from 0.00614 to 0.00595, saving model to saved_models/best_model_weights.hdf5\n",
      "143697/143697 [==============================] - 17s 121us/step - loss: 0.0038 - val_loss: 0.0060\n",
      "Epoch 11/20\n",
      "143488/143697 [============================>.] - ETA: 0s - loss: 0.0037Epoch 00011: val_loss did not improve\n",
      "143697/143697 [==============================] - 17s 119us/step - loss: 0.0037 - val_loss: 0.0061\n",
      "Epoch 12/20\n",
      "143488/143697 [============================>.] - ETA: 0s - loss: 0.0035Epoch 00012: val_loss did not improve\n",
      "143697/143697 [==============================] - 17s 119us/step - loss: 0.0035 - val_loss: 0.0061\n",
      "Epoch 13/20\n",
      "143488/143697 [============================>.] - ETA: 0s - loss: 0.0034Epoch 00013: val_loss did not improve\n",
      "143697/143697 [==============================] - 17s 119us/step - loss: 0.0034 - val_loss: 0.0061\n",
      "Epoch 14/20\n",
      "143488/143697 [============================>.] - ETA: 0s - loss: 0.0033Epoch 00014: val_loss did not improve\n",
      "143697/143697 [==============================] - 17s 119us/step - loss: 0.0033 - val_loss: 0.0061\n",
      "Epoch 15/20\n",
      "143488/143697 [============================>.] - ETA: 0s - loss: 0.0031Epoch 00015: val_loss did not improve\n",
      "143697/143697 [==============================] - 17s 119us/step - loss: 0.0031 - val_loss: 0.0061\n",
      "Epoch 16/20\n",
      "143360/143697 [============================>.] - ETA: 0s - loss: 0.0031Epoch 00016: val_loss did not improve\n",
      "143697/143697 [==============================] - 17s 119us/step - loss: 0.0031 - val_loss: 0.0060\n",
      "Epoch 17/20\n",
      "143488/143697 [============================>.] - ETA: 0s - loss: 0.0030Epoch 00017: val_loss did not improve\n",
      "143697/143697 [==============================] - 17s 119us/step - loss: 0.0030 - val_loss: 0.0060\n",
      "Epoch 18/20\n",
      "143360/143697 [============================>.] - ETA: 0s - loss: 0.0029Epoch 00018: val_loss did not improve\n",
      "143697/143697 [==============================] - 17s 119us/step - loss: 0.0029 - val_loss: 0.0061\n",
      "Epoch 19/20\n",
      "143488/143697 [============================>.] - ETA: 0s - loss: 0.0028Epoch 00019: val_loss did not improve\n",
      "143697/143697 [==============================] - 17s 119us/step - loss: 0.0028 - val_loss: 0.0060\n",
      "Epoch 20/20\n",
      "143360/143697 [============================>.] - ETA: 0s - loss: 0.0028Epoch 00020: val_loss did not improve\n",
      "143697/143697 [==============================] - 17s 120us/step - loss: 0.0028 - val_loss: 0.0062\n",
      "('Result on validation data: ', 1.9084107569696585)\n",
      "fittingNN_with_EntityEmbedding\n",
      "Train on 143697 samples, validate on 7563 samples\n",
      "Epoch 1/20\n",
      "143488/143697 [============================>.] - ETA: 0s - loss: 0.0100Epoch 00001: val_loss improved from inf to 0.00780, saving model to saved_models/best_model_weights.hdf5\n",
      "143697/143697 [==============================] - 18s 126us/step - loss: 0.0100 - val_loss: 0.0078\n",
      "Epoch 2/20\n",
      "143488/143697 [============================>.] - ETA: 0s - loss: 0.0074Epoch 00002: val_loss improved from 0.00780 to 0.00717, saving model to saved_models/best_model_weights.hdf5\n",
      "143697/143697 [==============================] - 17s 120us/step - loss: 0.0074 - val_loss: 0.0072\n",
      "Epoch 3/20\n",
      "143616/143697 [============================>.] - ETA: 0s - loss: 0.0064Epoch 00003: val_loss improved from 0.00717 to 0.00674, saving model to saved_models/best_model_weights.hdf5\n",
      "143697/143697 [==============================] - 17s 121us/step - loss: 0.0064 - val_loss: 0.0067\n",
      "Epoch 4/20\n",
      "143232/143697 [============================>.] - ETA: 0s - loss: 0.0058Epoch 00004: val_loss improved from 0.00674 to 0.00660, saving model to saved_models/best_model_weights.hdf5\n",
      "143697/143697 [==============================] - 17s 121us/step - loss: 0.0058 - val_loss: 0.0066\n",
      "Epoch 5/20\n",
      "143360/143697 [============================>.] - ETA: 0s - loss: 0.0053Epoch 00005: val_loss improved from 0.00660 to 0.00637, saving model to saved_models/best_model_weights.hdf5\n",
      "143697/143697 [==============================] - 17s 120us/step - loss: 0.0053 - val_loss: 0.0064\n",
      "Epoch 6/20\n",
      "143488/143697 [============================>.] - ETA: 0s - loss: 0.0049Epoch 00006: val_loss improved from 0.00637 to 0.00611, saving model to saved_models/best_model_weights.hdf5\n",
      "143697/143697 [==============================] - 17s 120us/step - loss: 0.0049 - val_loss: 0.0061\n",
      "Epoch 7/20\n",
      "143232/143697 [============================>.] - ETA: 0s - loss: 0.0045Epoch 00007: val_loss did not improve\n",
      "143697/143697 [==============================] - 17s 119us/step - loss: 0.0045 - val_loss: 0.0064\n",
      "Epoch 8/20\n",
      "143360/143697 [============================>.] - ETA: 0s - loss: 0.0042Epoch 00008: val_loss did not improve\n",
      "143697/143697 [==============================] - 17s 119us/step - loss: 0.0042 - val_loss: 0.0062\n",
      "Epoch 9/20\n",
      "143488/143697 [============================>.] - ETA: 0s - loss: 0.0040Epoch 00009: val_loss did not improve\n",
      "143697/143697 [==============================] - 17s 119us/step - loss: 0.0040 - val_loss: 0.0062\n",
      "Epoch 10/20\n",
      "143360/143697 [============================>.] - ETA: 0s - loss: 0.0038Epoch 00010: val_loss did not improve\n",
      "143697/143697 [==============================] - 17s 120us/step - loss: 0.0038 - val_loss: 0.0061\n",
      "Epoch 11/20\n",
      "143232/143697 [============================>.] - ETA: 0s - loss: 0.0036Epoch 00011: val_loss improved from 0.00611 to 0.00595, saving model to saved_models/best_model_weights.hdf5\n",
      "143697/143697 [==============================] - 18s 122us/step - loss: 0.0036 - val_loss: 0.0060\n",
      "Epoch 12/20\n",
      "143360/143697 [============================>.] - ETA: 0s - loss: 0.0035Epoch 00012: val_loss did not improve\n",
      "143697/143697 [==============================] - 17s 119us/step - loss: 0.0035 - val_loss: 0.0060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "143488/143697 [============================>.] - ETA: 0s - loss: 0.0034Epoch 00013: val_loss improved from 0.00595 to 0.00595, saving model to saved_models/best_model_weights.hdf5\n",
      "143697/143697 [==============================] - 17s 120us/step - loss: 0.0034 - val_loss: 0.0059\n",
      "Epoch 14/20\n",
      "143488/143697 [============================>.] - ETA: 0s - loss: 0.0033Epoch 00014: val_loss did not improve\n",
      "143697/143697 [==============================] - 17s 120us/step - loss: 0.0033 - val_loss: 0.0061\n",
      "Epoch 15/20\n",
      "143488/143697 [============================>.] - ETA: 0s - loss: 0.0031Epoch 00015: val_loss did not improve\n",
      "143697/143697 [==============================] - 17s 119us/step - loss: 0.0031 - val_loss: 0.0060\n",
      "Epoch 16/20\n",
      "143360/143697 [============================>.] - ETA: 0s - loss: 0.0030Epoch 00016: val_loss improved from 0.00595 to 0.00594, saving model to saved_models/best_model_weights.hdf5\n",
      "143697/143697 [==============================] - 17s 120us/step - loss: 0.0030 - val_loss: 0.0059\n",
      "Epoch 17/20\n",
      "143360/143697 [============================>.] - ETA: 0s - loss: 0.0030Epoch 00017: val_loss did not improve\n",
      "143697/143697 [==============================] - 17s 120us/step - loss: 0.0030 - val_loss: 0.0060\n",
      "Epoch 18/20\n",
      "143360/143697 [============================>.] - ETA: 0s - loss: 0.0029Epoch 00018: val_loss did not improve\n",
      "143697/143697 [==============================] - 17s 120us/step - loss: 0.0029 - val_loss: 0.0060\n",
      "Epoch 19/20\n",
      "143232/143697 [============================>.] - ETA: 0s - loss: 0.0028Epoch 00019: val_loss did not improve\n",
      "143697/143697 [==============================] - 17s 119us/step - loss: 0.0028 - val_loss: 0.0060\n",
      "Epoch 20/20\n",
      "143488/143697 [============================>.] - ETA: 0s - loss: 0.0028Epoch 00020: val_loss did not improve\n",
      "143697/143697 [==============================] - 17s 120us/step - loss: 0.0028 - val_loss: 0.0061\n",
      "('Result on validation data: ', 1.4585033204874289)\n",
      "fittingNN_with_EntityEmbedding\n",
      "Train on 143697 samples, validate on 7563 samples\n",
      "Epoch 1/20\n",
      "143360/143697 [============================>.] - ETA: 0s - loss: 0.0099Epoch 00001: val_loss improved from inf to 0.00779, saving model to saved_models/best_model_weights.hdf5\n",
      "143697/143697 [==============================] - 18s 128us/step - loss: 0.0099 - val_loss: 0.0078\n",
      "Epoch 2/20\n",
      "143488/143697 [============================>.] - ETA: 0s - loss: 0.0074Epoch 00002: val_loss improved from 0.00779 to 0.00706, saving model to saved_models/best_model_weights.hdf5\n",
      "143697/143697 [==============================] - 17s 120us/step - loss: 0.0074 - val_loss: 0.0071\n",
      "Epoch 3/20\n",
      "143488/143697 [============================>.] - ETA: 0s - loss: 0.0065Epoch 00003: val_loss improved from 0.00706 to 0.00661, saving model to saved_models/best_model_weights.hdf5\n",
      "143697/143697 [==============================] - 17s 120us/step - loss: 0.0065 - val_loss: 0.0066\n",
      "Epoch 4/20\n",
      "143488/143697 [============================>.] - ETA: 0s - loss: 0.0058Epoch 00004: val_loss improved from 0.00661 to 0.00637, saving model to saved_models/best_model_weights.hdf5\n",
      "143697/143697 [==============================] - 17s 121us/step - loss: 0.0058 - val_loss: 0.0064\n",
      "Epoch 5/20\n",
      "143488/143697 [============================>.] - ETA: 0s - loss: 0.0053Epoch 00005: val_loss improved from 0.00637 to 0.00630, saving model to saved_models/best_model_weights.hdf5\n",
      "143697/143697 [==============================] - 17s 121us/step - loss: 0.0053 - val_loss: 0.0063\n",
      "Epoch 6/20\n",
      "143360/143697 [============================>.] - ETA: 0s - loss: 0.0049Epoch 00006: val_loss did not improve\n",
      "143697/143697 [==============================] - 17s 119us/step - loss: 0.0049 - val_loss: 0.0063\n",
      "Epoch 7/20\n",
      "143488/143697 [============================>.] - ETA: 0s - loss: 0.0045Epoch 00007: val_loss improved from 0.00630 to 0.00625, saving model to saved_models/best_model_weights.hdf5\n",
      "143697/143697 [==============================] - 17s 120us/step - loss: 0.0045 - val_loss: 0.0062\n",
      "Epoch 8/20\n",
      "143232/143697 [============================>.] - ETA: 0s - loss: 0.0043Epoch 00008: val_loss improved from 0.00625 to 0.00616, saving model to saved_models/best_model_weights.hdf5\n",
      "143697/143697 [==============================] - 17s 121us/step - loss: 0.0043 - val_loss: 0.0062\n",
      "Epoch 9/20\n",
      "143360/143697 [============================>.] - ETA: 0s - loss: 0.0040Epoch 00009: val_loss improved from 0.00616 to 0.00611, saving model to saved_models/best_model_weights.hdf5\n",
      "143697/143697 [==============================] - 17s 120us/step - loss: 0.0040 - val_loss: 0.0061\n",
      "Epoch 10/20\n",
      "143488/143697 [============================>.] - ETA: 0s - loss: 0.0038Epoch 00010: val_loss improved from 0.00611 to 0.00606, saving model to saved_models/best_model_weights.hdf5\n",
      "143697/143697 [==============================] - 17s 120us/step - loss: 0.0038 - val_loss: 0.0061\n",
      "Epoch 11/20\n",
      "143360/143697 [============================>.] - ETA: 0s - loss: 0.0037Epoch 00011: val_loss improved from 0.00606 to 0.00602, saving model to saved_models/best_model_weights.hdf5\n",
      "143697/143697 [==============================] - 17s 122us/step - loss: 0.0037 - val_loss: 0.0060\n",
      "Epoch 12/20\n",
      "143488/143697 [============================>.] - ETA: 0s - loss: 0.0035Epoch 00012: val_loss did not improve\n",
      "143697/143697 [==============================] - 17s 119us/step - loss: 0.0035 - val_loss: 0.0060\n",
      "Epoch 13/20\n",
      "143360/143697 [============================>.] - ETA: 0s - loss: 0.0034Epoch 00013: val_loss did not improve\n",
      "143697/143697 [==============================] - 17s 119us/step - loss: 0.0034 - val_loss: 0.0063\n",
      "Epoch 14/20\n",
      "143360/143697 [============================>.] - ETA: 0s - loss: 0.0032Epoch 00014: val_loss improved from 0.00602 to 0.00588, saving model to saved_models/best_model_weights.hdf5\n",
      "143697/143697 [==============================] - 17s 121us/step - loss: 0.0032 - val_loss: 0.0059\n",
      "Epoch 15/20\n",
      "143488/143697 [============================>.] - ETA: 0s - loss: 0.0032Epoch 00015: val_loss did not improve\n",
      "143697/143697 [==============================] - 17s 119us/step - loss: 0.0032 - val_loss: 0.0061\n",
      "Epoch 16/20\n",
      "143360/143697 [============================>.] - ETA: 0s - loss: 0.0030Epoch 00016: val_loss did not improve\n",
      "143697/143697 [==============================] - 17s 119us/step - loss: 0.0030 - val_loss: 0.0062\n",
      "Epoch 17/20\n",
      "143360/143697 [============================>.] - ETA: 0s - loss: 0.0030Epoch 00017: val_loss did not improve\n",
      "143697/143697 [==============================] - 17s 119us/step - loss: 0.0030 - val_loss: 0.0063\n",
      "Epoch 18/20\n",
      "143360/143697 [============================>.] - ETA: 0s - loss: 0.0029Epoch 00018: val_loss did not improve\n",
      "143697/143697 [==============================] - 17s 119us/step - loss: 0.0029 - val_loss: 0.0061\n",
      "Epoch 19/20\n",
      "143232/143697 [============================>.] - ETA: 0s - loss: 0.0028Epoch 00019: val_loss did not improve\n",
      "143697/143697 [==============================] - 17s 119us/step - loss: 0.0028 - val_loss: 0.0060\n",
      "Epoch 20/20\n",
      "143232/143697 [============================>.] - ETA: 0s - loss: 0.0028Epoch 00020: val_loss did not improve\n",
      "143697/143697 [==============================] - 17s 119us/step - loss: 0.0028 - val_loss: 0.0060\n",
      "('Result on validation data: ', 1.9078280463981949)\n"
     ]
    }
   ],
   "source": [
    "file_object.finding_best_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=file_object.get_best_model()\n",
    "file_object.update_best_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess= file_object.get_preporcessed_file()\n",
    "preprocess.get_dim()\n",
    "pre_x= preprocess.get_pre_x()\n",
    "pre_y= preprocess.get_pre_y()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pre_x : categorical to nominal convert "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "key= file_object.get_prediction_key()\n",
    "\n",
    "def categorical_to_nominal(df, variable, key):\n",
    "        # copythe code from preporcess.py\n",
    "        # self.df       self.key   self.variables\n",
    "        \n",
    "        for x in variable:\n",
    "\n",
    "            if (\"int\" in str(type(np.array(df[x])[1]))) or (\"float\" in str(type(np.array(df[x])[1]))) or (\"long\" in str(type(np.array(df[x])[1]))):\n",
    "\n",
    "                pass\n",
    "            else:\n",
    "                print(x)\n",
    "                df[[x]], key =nom_convert_int(df[[x]],x, key)\n",
    "              \n",
    "        print(\"categoricol to nominal done!\")\n",
    "        return df, key\n",
    "    \n",
    "def nom_convert_int(df,x, key):\n",
    "        x_c= np.array(df)\n",
    "        dic=key[x]\n",
    "        try:\n",
    "            value_temp=max(key[x].values())+1\n",
    "            print(len(x_c))\n",
    "            for j in range(len(x_c)):\n",
    "                try: \n",
    "                    x_c[j][0]=dic[x_c[j][0]]\n",
    "                except:\n",
    "                    dic[x_c[j][0]]= value_temp\n",
    "                    value_temp= value_temp+1\n",
    "                    x_c[j][0]=dic[x_c[j][0]]\n",
    "            key[x]= dic\n",
    "        except:\n",
    "            pass\n",
    "        return x_c , key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Division</th>\n",
       "      <th>Season</th>\n",
       "      <th>Product Type</th>\n",
       "      <th>Customer Type Description</th>\n",
       "      <th>Customer #</th>\n",
       "      <th>Label (Style Mst)</th>\n",
       "      <th>Label Desc. (Order Detail)</th>\n",
       "      <th>Category Description</th>\n",
       "      <th>STYLE #</th>\n",
       "      <th>Order Type Desc</th>\n",
       "      <th>Date Startyearrr</th>\n",
       "      <th>Date Startmonthhh</th>\n",
       "      <th>Date Startdayyy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4494</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4494</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>4494</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4494</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4494</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4494</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4494</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4494</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4494</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3062</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4494</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3063</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4494</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3064</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4494</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3072</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4494</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3073</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4494</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3074</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4494</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3075</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4494</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3083</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4494</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3084</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4494</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3085</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4494</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3092</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4494</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3093</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4494</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3094</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4494</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3095</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4494</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3600</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4494</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3607</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4494</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3608</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4494</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3609</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4494</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3610</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4494</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3611</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4494</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3612</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4494</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97494</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>453</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4494</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97623</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>454</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4494</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98318</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4494</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98412</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>715</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4494</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98541</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>716</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4494</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98747</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>626</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4494</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99123</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4494</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99265</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>627</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4494</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99530</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>628</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4494</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101162</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>576</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4494</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101398</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>472</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4494</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101399</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>472</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4494</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101400</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>472</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4494</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101625</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>473</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4494</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102295</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>632</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4494</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102534</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>721</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4494</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102601</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>490</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4494</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102741</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>633</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4494</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103233</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>509</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4494</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103349</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>513</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4494</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103529</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>515</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4494</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103530</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>515</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4494</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103722</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>521</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4494</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103806</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>578</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4494</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103983</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>727</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4494</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104218</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>523</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4494</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104219</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>523</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4494</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104368</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>525</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4494</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104749</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4494</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104750</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4494</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>623 rows  13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Division  Season  Product Type  Customer Type Description  Customer #  \\\n",
       "3              0       1             0                          0           0   \n",
       "4              0       1             0                          0           0   \n",
       "8              0       1             0                          0           0   \n",
       "9              0       1             0                          0           0   \n",
       "11             0       1             0                          0           0   \n",
       "12             0       1             0                          0           0   \n",
       "14             0       1             0                          0           0   \n",
       "15             0       1             0                          0           0   \n",
       "2098           0       1             0                          0           2   \n",
       "3062           0       1             0                          0         128   \n",
       "3063           0       1             0                          0         128   \n",
       "3064           0       1             0                          0         128   \n",
       "3072           0       1             0                          0         128   \n",
       "3073           0       1             0                          0         128   \n",
       "3074           0       1             0                          0         128   \n",
       "3075           0       1             0                          0         128   \n",
       "3083           0       1             0                          0         128   \n",
       "3084           0       1             0                          0         128   \n",
       "3085           0       1             0                          0         128   \n",
       "3092           0       1             0                          0         128   \n",
       "3093           0       1             0                          0         128   \n",
       "3094           0       1             0                          0         128   \n",
       "3095           0       1             0                          0         128   \n",
       "3600           0       1             0                          0           1   \n",
       "3607           0       1             0                          0           1   \n",
       "3608           0       1             0                          0           1   \n",
       "3609           0       1             0                          0           1   \n",
       "3610           0       1             0                          0           1   \n",
       "3611           0       1             0                          0           1   \n",
       "3612           0       1             0                          0           1   \n",
       "...          ...     ...           ...                        ...         ...   \n",
       "97494          0       1             0                          1         453   \n",
       "97623          0       1             0                          1         454   \n",
       "98318          0       1             0                          1         111   \n",
       "98412          0       1             0                          1         715   \n",
       "98541          0       1             0                          1         716   \n",
       "98747          0       1             0                          1         626   \n",
       "99123          0       1             0                          1         112   \n",
       "99265          0       1             0                          1         627   \n",
       "99530          0       1             0                          1         628   \n",
       "101162         0       1             0                          1         576   \n",
       "101398         0       1             0                          1         472   \n",
       "101399         0       1             0                          1         472   \n",
       "101400         0       1             0                          1         472   \n",
       "101625         0       1             0                          1         473   \n",
       "102295         0       1             0                          1         632   \n",
       "102534         0       1             0                          1         721   \n",
       "102601         0       1             0                          1         490   \n",
       "102741         0       1             0                          1         633   \n",
       "103233         0       1             0                          1         509   \n",
       "103349         0       1             0                          1         513   \n",
       "103529         0       1             0                          1         515   \n",
       "103530         0       1             0                          1         515   \n",
       "103722         0       1             0                          1         521   \n",
       "103806         0       1             0                          1         578   \n",
       "103983         0       1             0                          1         727   \n",
       "104218         0       1             0                          1         523   \n",
       "104219         0       1             0                          1         523   \n",
       "104368         0       1             0                          1         525   \n",
       "104749         0       1             0                          2           9   \n",
       "104750         0       1             0                          2           9   \n",
       "\n",
       "        Label (Style Mst)  Label Desc. (Order Detail)  Category Description  \\\n",
       "3                       0                           0                     0   \n",
       "4                       0                           0                     0   \n",
       "8                       0                           0                    25   \n",
       "9                       0                           0                     0   \n",
       "11                      0                           0                     0   \n",
       "12                      0                           0                     0   \n",
       "14                      0                           0                     0   \n",
       "15                      0                           0                     0   \n",
       "2098                    0                           0                     0   \n",
       "3062                    0                           0                     0   \n",
       "3063                    0                           0                     0   \n",
       "3064                    0                           0                     0   \n",
       "3072                    0                           0                     0   \n",
       "3073                    0                           0                     0   \n",
       "3074                    0                           0                     0   \n",
       "3075                    0                           0                     0   \n",
       "3083                    0                           0                     0   \n",
       "3084                    0                           0                     0   \n",
       "3085                    0                           0                     0   \n",
       "3092                    0                           0                     0   \n",
       "3093                    0                           0                     0   \n",
       "3094                    0                           0                     0   \n",
       "3095                    0                           0                     0   \n",
       "3600                    0                           0                     0   \n",
       "3607                    0                           0                     0   \n",
       "3608                    0                           0                     0   \n",
       "3609                    0                           0                     0   \n",
       "3610                    0                           0                     0   \n",
       "3611                    0                           0                     0   \n",
       "3612                    0                           0                     0   \n",
       "...                   ...                         ...                   ...   \n",
       "97494                   0                           0                     0   \n",
       "97623                   0                           0                     0   \n",
       "98318                   0                           0                     0   \n",
       "98412                   0                           0                     0   \n",
       "98541                   0                           0                     0   \n",
       "98747                   0                           0                     0   \n",
       "99123                   0                           0                     0   \n",
       "99265                   0                           0                     0   \n",
       "99530                   0                           0                     0   \n",
       "101162                  0                           0                     0   \n",
       "101398                  0                           0                     0   \n",
       "101399                  0                           0                     0   \n",
       "101400                  0                           0                     0   \n",
       "101625                  0                           0                     0   \n",
       "102295                  0                           0                     0   \n",
       "102534                  0                           0                     0   \n",
       "102601                  0                           0                     0   \n",
       "102741                  0                           0                     0   \n",
       "103233                  0                           0                     0   \n",
       "103349                  0                           0                     0   \n",
       "103529                  0                           0                     0   \n",
       "103530                  0                           0                     0   \n",
       "103722                  0                           0                     0   \n",
       "103806                  0                           0                     0   \n",
       "103983                  0                           0                     0   \n",
       "104218                  0                           0                     0   \n",
       "104219                  0                           0                     0   \n",
       "104368                  0                           0                     0   \n",
       "104749                  0                           0                     0   \n",
       "104750                  0                           0                     0   \n",
       "\n",
       "        STYLE #  Order Type Desc  Date Startyearrr  Date Startmonthhh  \\\n",
       "3          4494                0              2017                 12   \n",
       "4          4494                0              2017                  3   \n",
       "8          4494                0              2017                 12   \n",
       "9          4494                0              2017                  3   \n",
       "11         4494                0              2017                 12   \n",
       "12         4494                0              2017                  3   \n",
       "14         4494                0              2017                 12   \n",
       "15         4494                0              2017                  3   \n",
       "2098       4494                0              2017                  3   \n",
       "3062       4494                2              2017                  7   \n",
       "3063       4494                2              2017                  3   \n",
       "3064       4494                2              2017                  3   \n",
       "3072       4494                2              2017                  7   \n",
       "3073       4494                2              2017                  3   \n",
       "3074       4494                2              2017                  3   \n",
       "3075       4494                0              2017                  3   \n",
       "3083       4494                2              2017                  7   \n",
       "3084       4494                2              2017                  3   \n",
       "3085       4494                2              2017                  3   \n",
       "3092       4494                2              2017                  7   \n",
       "3093       4494                2              2017                  3   \n",
       "3094       4494                2              2017                  3   \n",
       "3095       4494                0              2017                  7   \n",
       "3600       4494                2              2017                  5   \n",
       "3607       4494                2              2017                  5   \n",
       "3608       4494                2              2017                 12   \n",
       "3609       4494                2              2017                  3   \n",
       "3610       4494                0              2017                  5   \n",
       "3611       4494                0              2017                 12   \n",
       "3612       4494                2              2017                  3   \n",
       "...         ...              ...               ...                ...   \n",
       "97494      4494                0              2017                  5   \n",
       "97623      4494                0              2017                  4   \n",
       "98318      4494                1              2017                  4   \n",
       "98412      4494                1              2017                  3   \n",
       "98541      4494                1              2017                  3   \n",
       "98747      4494                1              2017                  3   \n",
       "99123      4494                1              2017                  3   \n",
       "99265      4494                1              2017                 10   \n",
       "99530      4494                1              2017                  3   \n",
       "101162     4494                1              2017                  3   \n",
       "101398     4494                1              2017                  3   \n",
       "101399     4494                0              2017                 12   \n",
       "101400     4494                1              2017                  5   \n",
       "101625     4494                0              2017                  4   \n",
       "102295     4494                1              2017                  3   \n",
       "102534     4494                1              2017                  4   \n",
       "102601     4494                0              2017                  2   \n",
       "102741     4494                1              2017                  3   \n",
       "103233     4494                1              2017                  5   \n",
       "103349     4494                1              2017                  3   \n",
       "103529     4494                2              2017                  5   \n",
       "103530     4494                2              2017                  5   \n",
       "103722     4494                2              2017                  1   \n",
       "103806     4494                1              2017                  3   \n",
       "103983     4494                1              2017                  3   \n",
       "104218     4494                2              2017                  3   \n",
       "104219     4494                1              2017                  1   \n",
       "104368     4494                1              2017                  3   \n",
       "104749     4494                1              2017                  1   \n",
       "104750     4494                1              2017                  1   \n",
       "\n",
       "        Date Startdayyy  \n",
       "3                     3  \n",
       "4                    24  \n",
       "8                     3  \n",
       "9                    24  \n",
       "11                    3  \n",
       "12                   24  \n",
       "14                    3  \n",
       "15                   24  \n",
       "2098                 14  \n",
       "3062                  3  \n",
       "3063                 14  \n",
       "3064                 21  \n",
       "3072                  3  \n",
       "3073                 14  \n",
       "3074                 21  \n",
       "3075                 14  \n",
       "3083                  3  \n",
       "3084                 14  \n",
       "3085                 21  \n",
       "3092                  3  \n",
       "3093                 14  \n",
       "3094                 21  \n",
       "3095                  3  \n",
       "3600                  3  \n",
       "3607                  3  \n",
       "3608                  3  \n",
       "3609                 19  \n",
       "3610                  3  \n",
       "3611                  3  \n",
       "3612                 19  \n",
       "...                 ...  \n",
       "97494                31  \n",
       "97623                18  \n",
       "98318                25  \n",
       "98412                25  \n",
       "98541                25  \n",
       "98747                25  \n",
       "99123                25  \n",
       "99265                 4  \n",
       "99530                25  \n",
       "101162               25  \n",
       "101398               25  \n",
       "101399                4  \n",
       "101400               25  \n",
       "101625               18  \n",
       "102295               25  \n",
       "102534               25  \n",
       "102601                5  \n",
       "102741               25  \n",
       "103233               15  \n",
       "103349               25  \n",
       "103529               27  \n",
       "103530               27  \n",
       "103722                5  \n",
       "103806               25  \n",
       "103983               25  \n",
       "104218               26  \n",
       "104219                5  \n",
       "104368               25  \n",
       "104749                5  \n",
       "104750                5  \n",
       "\n",
       "[623 rows x 13 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categoricol to nominal done!\n"
     ]
    }
   ],
   "source": [
    "pass_to_model, key[2]= categorical_to_nominal(pre_x, key[1], key[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<models.NN_with_EntityEmbedding at 0x7fda1045ced0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model= file_object.get_best_model()\n",
    "model= model['NN_with_EntityEmbedding'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"aaron_trained_model.pickle\", 'w') as f:\n",
    "        pickle.dump(model.get_model(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   4.27753019,    1.79900897,    3.74146581,    1.79900897,\n",
       "          4.27753019,    1.79900897,    4.27753019,    1.79900897,\n",
       "         42.52225876,   66.32046509,   33.57078171,  104.07780457,\n",
       "         66.32046509,   33.57078171,  104.07780457,    9.88801289,\n",
       "         66.32046509,   33.57078171,  104.07780457,   66.32046509,\n",
       "         33.57078171,  104.07780457,    5.12975311,   34.63320541,\n",
       "         34.63320541,   14.20201302,    6.24412155,   11.16394806,\n",
       "          3.71779943,    6.24412155,   11.16394806,   12.43873501,\n",
       "         11.56527233,    5.73448849,    9.01505089,   11.56527233,\n",
       "          5.73448849,   11.56527233,    5.73448849,   11.56527233,\n",
       "          5.73448849,   11.19163513,    9.68987179,   12.43873501,\n",
       "         11.56527233,   11.56527233,   11.56527233,    5.73448849,\n",
       "          5.73448849,   11.56527233,    5.73448849,   16.15175438,\n",
       "         10.79000378,   18.99057388,   16.15175438,   10.79000378,\n",
       "         18.99057388,   16.15175438,   10.79000378,   18.99057388,\n",
       "         16.15175438,   10.79000378,   18.99057388,   16.15175438,\n",
       "         10.79000378,   32.72247314,   15.41524982,   16.15175438,\n",
       "         10.79000378,   18.99057388,   16.15175438,   10.79000378,\n",
       "         18.99057388,   17.15481567,   32.27037811,   30.70788002,\n",
       "         30.80784035,   36.51308823,    1.29502022,    1.09158599,\n",
       "         14.71595001,    7.66702127,    3.36489701,    3.19011903,\n",
       "          2.2704432 ,    4.47867489,    3.7158277 ,    3.13786793,\n",
       "          9.55322742,    2.44719887,    3.16834259,    3.13786793,\n",
       "          9.55322742,    2.44719887,    8.20084763,    8.81309128,\n",
       "          4.17634344,    4.34042406,    1.50206602,   75.85557556,\n",
       "          2.97968292,    2.79036856,    3.3105607 ,    1.56510401,\n",
       "          2.21026134,    5.57922125,   28.16737938,    4.85403204,\n",
       "         11.31167793,   35.42432022,   18.08117294,   40.08463287,\n",
       "         86.95383453,   25.28273201,   45.80109024,    7.05538177,\n",
       "         11.22790527,    2.57881474,    2.57881474,    7.95915222,\n",
       "          7.55624151,    2.56442046,    1.89597201,    2.32944512,\n",
       "          4.85100317,    2.56442046,    1.89597201,    2.32944512,\n",
       "          4.85100317,    5.900002  ,    2.56442046,    2.32944512,\n",
       "          5.900002  ,    2.56442046,    1.89597201,    7.97673941,\n",
       "         22.97900772,    7.97673941,    7.97673941,   18.11229515,\n",
       "          7.97673941,    7.97673941,    7.97673941,    7.97673941,\n",
       "         41.21251297,   11.3976593 ,   45.20807648,   58.50087738,\n",
       "        106.86358643,   86.47737122,  112.60461426,   22.80983925,\n",
       "         48.45330048,   66.48580933,   34.57200623,   42.82134628,\n",
       "         91.22291565,   71.74632263,  106.98595428,  154.11927795,\n",
       "         22.80983925,   48.45330048,   66.48580933,   34.57200623,\n",
       "         42.82134628,   91.22291565,   71.74632263,  106.98595428,\n",
       "        154.11927795,   22.80983925,   12.72052383,   48.45330048,\n",
       "         66.48580933,   34.57200623,   42.82134628,   91.22291565,\n",
       "         71.74632263,  106.98595428,  154.11927795,   22.80983925,\n",
       "         12.72052383,   48.45330048,   66.48580933,   34.57200623,\n",
       "         42.82134628,   91.22291565,   71.74632263,  106.98595428,\n",
       "        154.11927795,   12.87648201,   67.24082184,   61.77842712,\n",
       "         18.73595619,   31.32228279,   10.75288963,   73.14091492,\n",
       "         17.12841415,    8.15250874,    2.90193796,    8.67959023,\n",
       "          9.40058994,   10.75288963,   73.14091492,    2.90193796,\n",
       "          8.67959023,    9.37635517,    9.40058994,   10.75288963,\n",
       "         73.14091492,   23.68397713,   17.12841415,    8.15250874,\n",
       "         28.79969788,   69.11805725,   25.04181862,  223.87705994,\n",
       "         14.46752167,   12.348279  ,    7.7770772 ,   15.04242897,\n",
       "         20.54443169,    7.97673941,   80.87808228,   69.11805725,\n",
       "         24.96822929,  223.87705994,  109.47694397,   12.348279  ,\n",
       "         39.52007675,   53.21295166,   20.54443169,   22.97900772,\n",
       "         80.87808228,   69.11805725,   14.46752167,   12.348279  ,\n",
       "          7.7770772 ,   15.04242897,   80.87808228,   69.11805725,\n",
       "        223.87705994,   14.46752167,    7.7770772 ,   15.04242897,\n",
       "         20.54443169,    7.97673941,   80.87808228,   69.11805725,\n",
       "         25.04181862,  223.87705994,   14.46752167,   12.348279  ,\n",
       "          7.7770772 ,   15.04242897,   20.54443169,    7.97673941,\n",
       "         80.87808228,   69.11805725,   28.79969788,   14.15927505,\n",
       "        167.04029846,   12.348279  ,   13.85259151,   17.97246552,\n",
       "         39.07030869,   18.11229515,    9.76713467,   69.11805725,\n",
       "        223.87705994,   12.348279  ,    7.7770772 ,   15.04242897,\n",
       "         20.54443169,    7.97673941,   80.87808228,   69.11805725,\n",
       "          4.02305317,  223.87705994,   14.46752167,   12.348279  ,\n",
       "          7.7770772 ,   15.04242897,   20.54443169,    7.97673941,\n",
       "          4.02305317,  223.87705994,   14.46752167,   12.348279  ,\n",
       "          7.7770772 ,   15.04242897,   20.54443169,    7.97673941,\n",
       "         80.87808228,   69.11805725,    4.02305317,  223.87705994,\n",
       "         12.348279  ,    7.7770772 ,   15.04242897,   20.54443169,\n",
       "          7.97673941,   80.87808228,   69.11805725,   18.11333466,\n",
       "         18.18098068,   18.11333466,   18.18098068,   18.11333466,\n",
       "         18.18098068,   18.11333466,   18.18098068,   32.30856323,\n",
       "         18.11333466,   18.18098068,   18.11333466,   18.18098068,\n",
       "          3.77198195,    3.46343279,    2.53592443,    2.06998396,\n",
       "          1.81350136,    1.99934769,    3.33147621,    1.90762949,\n",
       "          3.77198195,    1.61441791,    3.46343279,    2.53592443,\n",
       "          2.06998396,    2.16018891,   16.88707924,   36.93537521,\n",
       "         13.33108902,   13.33108902,    9.7428627 ,   23.42031479,\n",
       "         20.60398674,   20.60398674,    5.900002  ,    5.900002  ,\n",
       "         15.37301254,   13.6981287 ,   13.93185139,   16.82629395,\n",
       "          8.99495888,    7.55589581,   12.42446613,   19.12933731,\n",
       "         15.37301254,   13.6981287 ,   13.93185139,   16.82629395,\n",
       "          8.99495888,    7.55589581,   12.42446613,   19.12933731,\n",
       "         15.37301254,   13.6981287 ,   13.93185139,   16.82629395,\n",
       "          8.99495888,    7.55589581,   12.42446613,   19.12933731,\n",
       "         15.37301254,   13.6981287 ,   13.93185139,   16.82629395,\n",
       "          8.99495888,    7.55589581,   12.42446613,   19.12933731,\n",
       "         15.37301254,   13.6981287 ,   13.93185139,   16.82629395,\n",
       "          8.99495888,    6.87870502,   12.42446613,   19.12933731,\n",
       "         15.37301254,   13.6981287 ,   13.93185139,   16.82629395,\n",
       "          8.99495888,    7.55589581,   12.42446613,   19.12933731,\n",
       "         15.37301254,   13.6981287 ,   13.93185139,   16.82629395,\n",
       "          8.99495888,    7.55589581,   12.42446613,   19.12933731,\n",
       "          9.96378803,    6.27111864,    6.27111864,   48.84954453,\n",
       "         19.92193222,   51.56998062,   34.82046127,   35.17205811,\n",
       "         29.04430199,   14.96445179,   38.61097336,   63.78670502,\n",
       "         16.94895554,   96.08958435,   96.08958435,   81.935112  ,\n",
       "         66.22534943,  127.05041504,   46.04243088,   56.80807877,\n",
       "        101.26570129,   30.24467468,    3.85964036,    5.10673857,\n",
       "          7.65290403,    1.15691125,    1.86975205,    1.20302808,\n",
       "          6.96086025,    4.80103445,   14.45295143,   14.45295143,\n",
       "         13.27174187,   37.14796448,   41.6988678 ,    7.9096384 ,\n",
       "         20.11109734,   20.4933815 ,    1.62530971,   10.75249004,\n",
       "         13.46391296,    6.39639235,    4.34497738,    7.57951736,\n",
       "          6.22865391,   27.15725708,    7.38307142,    6.16942549,\n",
       "         14.79016399,   15.43353844,   10.88754559,   10.34930229,\n",
       "          3.33077145,   13.02163219,   11.87436008,    2.68147731,\n",
       "          6.20122051,   11.78906441,    3.30276537,   27.51244354,\n",
       "         11.22693062,   13.93142986,    4.35726023,    6.60204077,\n",
       "         13.78684235,    9.83568859,   16.02640343,   19.58547401,\n",
       "         10.02085495,    3.60232973,    3.51908755,   15.05045414,\n",
       "          9.83532238,    3.66658688,    6.89565659,   10.33971977,\n",
       "         12.86431503,    9.18942261,   11.85524273,   23.3535881 ,\n",
       "          9.70925617,   11.82242775,    9.40151405,   28.77513313,\n",
       "         42.98457718,   12.95073414,   19.6828804 ,    6.76103258,\n",
       "         11.69965839,    3.72782469,   21.15153122,   22.65851212,\n",
       "         12.82853794,   13.9024229 ,   16.26643753,   19.99069977,\n",
       "          9.66810608,    3.53937364,    5.14038992,    8.93968582,\n",
       "          8.98375416,    2.17933941,   12.01490116,   12.21683884,\n",
       "          6.24975586,   22.20649719,   15.55404758,   22.85063553,\n",
       "          9.49363041,   12.89622498,    4.20411777,    3.40502667,\n",
       "         10.59077358,    8.43186188,    2.53935051,    9.87531853,\n",
       "         13.29865551,    7.62821341,   39.59344101,   10.24465847,\n",
       "         10.24465847,    7.56127501,   32.4553833 ,    7.86793709,\n",
       "          3.0716784 ,   13.2006588 ,    9.32890415,    4.75476599,\n",
       "         12.60441208,    9.07567596,   11.77957153,   11.31965256,\n",
       "         13.75327969,   11.38195038,   10.16770744,   10.16770744,\n",
       "          2.99370241,   10.08255577,    7.99910355,   10.29966736,\n",
       "         28.78270149,   11.65380478,    4.23281145,   13.70881557,\n",
       "         12.01786041,   11.74055862,    4.65470839,    4.40106869,\n",
       "          8.13669109,   10.78621292,    3.89365506,   14.36160278,\n",
       "          6.95870399,    5.47456169,   42.0579834 ,   20.78109741,\n",
       "         16.3940258 ,   14.51458073,    7.73858881,   33.69287109,\n",
       "         36.73811722,    6.00245333,   14.61009693,   14.04927063,\n",
       "         10.90014744,  121.6740036 ,    2.25532246,    2.19721627,\n",
       "          1.75971317,    3.17590213,    3.26777101,    6.86272812,\n",
       "          4.18306589,   11.94090557,   15.26728821,   14.13615227,\n",
       "         14.06307793,    8.28914928,   11.68013   ,   12.50200653,\n",
       "         19.06551933,   11.47594357,   13.14292908,    7.41814041,\n",
       "         10.18524647,   12.00856686,    7.24861336,    7.5490551 ,\n",
       "          1.35600793,    1.1182307 ,   19.08651924,    3.78444457,\n",
       "          1.52540338,    1.74336696,   92.3974762 ,   45.56069183,\n",
       "          7.11373949,    7.34470701,    8.50003815,   11.43207836,\n",
       "          7.75608826,    4.27688932,   11.88825703,   13.14713097,\n",
       "          3.5302434 ,    8.84196758,    3.38671064,   13.67068386,\n",
       "          3.37025595,   10.25954914,   10.61912441,    7.81158972,\n",
       "          4.86227751,   18.13107491,   11.31422138,   11.96562576,\n",
       "          3.625103  ,   25.51353073,   25.51353073,    6.82302237,\n",
       "          8.68501568,   12.76516914,   17.37466049,    8.77977753,\n",
       "         14.18452549,   29.18689156,   29.18689156], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mdl.fit(pass_to_model[:5], pre_y[:5],preprocess.get_test_x , preprocess.get_test_y)\n",
    "guessed= mdl.guess(np.array(pass_to_model))\n",
    "guessed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~ms8909/10.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plotly.tools.set_credentials_file(username='ms8909', api_key='OOQ413hzFuXQFdeEbpJK')\n",
    "\n",
    "x_temp = []\n",
    "for i in range(len(guessed)):\n",
    "    x_temp.append(i)\n",
    "data = []\n",
    "trace1 = go.Scatter(\n",
    "        x=x_temp,\n",
    "        y=guessed,\n",
    "        mode='lines',\n",
    "        name='predicted Sales'\n",
    "        )\n",
    "data.append(trace1)\n",
    "\n",
    "trace2 = go.Scatter(\n",
    "            x=x_temp,\n",
    "            y=pre_y,\n",
    "            mode='lines',\n",
    "            name='actual'\n",
    "        )\n",
    "\n",
    "data.append(trace2)\n",
    "\n",
    "fig = dict(data=data)\n",
    "py.iplot(fig, filename='line-mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11548\n",
      "15240.4294145\n"
     ]
    }
   ],
   "source": [
    "print(sum(pre_y))\n",
    "print(sum(guessed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12,  3, 12,  3, 12,  3, 12,  3,  3,  7,  3,  3,  7,  3,  3,  3,  7,\n",
       "        3,  3,  7,  3,  3,  7,  5,  5, 12,  3,  5, 12,  3,  5,  3,  8,  3,\n",
       "        1,  8,  3,  8,  3,  8,  3,  2,  9,  3,  8,  8,  8,  3,  3,  8,  3,\n",
       "        3,  7,  3,  3,  7,  3,  3,  7,  3,  3,  7,  3,  3,  7,  3,  3,  3,\n",
       "        7,  3,  3,  7,  3,  3,  7,  3,  3,  3,  3,  3,  3,  3,  3,  6,  3,\n",
       "        1,  1,  9,  3,  3,  2,  9,  3,  3,  2,  3,  1,  3,  7,  1,  3,  3,\n",
       "        3,  3,  1, 10,  1,  3, 12,  3,  3,  1,  4,  4,  5,  9,  5, 10, 10,\n",
       "        4,  1,  3,  4,  3, 10,  3,  4,  3, 10,  5,  3,  3,  5,  3,  4,  5,\n",
       "        5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  3, 11,  4,  9,  5,  3,  4,\n",
       "       11,  4,  4,  3,  9,  5,  5,  3,  4, 11,  4,  4,  3,  9,  5,  5,  3,\n",
       "        1,  4, 11,  4,  4,  3,  9,  5,  5,  3,  1,  4, 11,  4,  4,  3,  9,\n",
       "        5,  5,  3,  2,  9,  4,  4,  4,  5,  5,  5,  3,  9,  4,  4,  5,  3,\n",
       "        9,  4,  4,  4,  5,  7,  5,  5,  3,  5,  3,  5, 10,  4,  4,  1,  9,\n",
       "        5,  5,  5,  3,  5, 11,  4,  4,  2,  9,  5,  5,  5, 10,  4,  4,  1,\n",
       "        5,  5,  5, 10,  4,  1,  9,  5,  5,  5,  3,  5, 10,  4,  4,  1,  9,\n",
       "        5,  5,  5,  3,  6, 12,  4,  4,  3, 10,  5,  5,  5,  5,  4,  4,  1,\n",
       "        9,  5,  5,  5,  3,  5, 10,  4,  4,  1,  9,  5,  3,  5, 10,  4,  4,\n",
       "        1,  9,  5,  5,  5,  3,  5,  4,  4,  1,  9,  5,  5,  5,  3,  5,  3,\n",
       "        5,  3,  5,  3,  5,  5,  3,  5,  3,  5,  6,  4,  4,  4,  5,  5,  5,\n",
       "        3,  6,  4,  4,  4,  4, 11,  4,  1,  4,  4,  4,  1,  2,  2,  5,  5,\n",
       "        4,  4,  4,  4, 11,  5,  5,  5,  4,  4,  4,  4, 11,  5,  5,  5,  4,\n",
       "        4,  4,  4, 11,  5,  5,  5,  4,  4,  4,  4, 11,  5,  5,  5,  4,  4,\n",
       "        4,  4, 11,  5,  5,  5,  4,  4,  4,  4, 11,  5,  5,  5,  4,  4,  4,\n",
       "        4, 11,  5,  5,  5,  1,  1,  1,  5,  4,  4,  4,  4, 11,  5,  5,  5,\n",
       "        1,  3,  3,  3,  5,  5,  3,  4,  8,  4,  3,  3,  3,  3,  4,  5,  1,\n",
       "        1,  3,  3,  3,  3,  4,  3,  3,  3,  3,  4,  4,  4,  4,  6,  3,  4,\n",
       "        4,  3,  3,  3,  3,  4,  3,  4,  3,  5,  3,  4,  3,  5,  5,  1,  3,\n",
       "        4,  3,  3,  3,  4,  3,  3,  3,  3,  3,  3,  3,  3,  3,  1,  4,  5,\n",
       "        4,  3,  3,  5,  5,  3,  3,  4,  1,  4,  4,  3,  2,  5,  5,  5,  3,\n",
       "        1,  4, 12,  1,  5, 11,  4,  2,  5,  3,  4,  3,  3,  3,  3,  3,  4,\n",
       "        3,  4,  3,  3,  3,  3,  3,  3,  5,  3,  3,  3,  5,  5,  3,  3,  3,\n",
       "        3,  6,  1,  4,  4,  4,  5,  5,  5,  3,  5,  8,  4,  3,  4,  3,  4,\n",
       "        3,  3,  3,  4,  3,  5,  3,  3,  1,  3,  3,  4,  5,  1,  3,  5,  3,\n",
       "        3,  4, 11,  5,  5,  3,  4,  5,  3, 10,  1,  3,  3,  7,  5,  1,  8,\n",
       "        5,  3,  5,  4,  3,  4,  3,  7,  5,  1,  8,  5,  1,  1,  4,  5,  4,\n",
       "        4,  3,  3,  3,  3, 10,  3,  3,  3, 12,  5,  4,  3,  4,  2,  3,  5,\n",
       "        3,  5,  5,  1,  3,  3,  3,  1,  3,  1,  1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(pass_to_model['Date Startmonthhh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_r={1:0,2:0,3:0,4:0,5:0,6:0,7:0,8:0,9:0, 10:0,11:0,12:0}\n",
    "dic_f={1:0,2:0,3:0,4:0,5:0,6:0,7:0,8:0,9:0, 10:0,11:0,12:0}\n",
    "count=0\n",
    "for i in np.array(pass_to_model['Date Startmonthhh']):\n",
    "    dic_r[i]= dic_r[i]+ pre_y[count]\n",
    "    dic_f[i]= dic_f[i]+ guessed[count]\n",
    "    count= count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 762.65596795082092,\n",
       " 2: 221.43194103240967,\n",
       " 3: 3492.7388317584991,\n",
       " 4: 2250.3106162548065,\n",
       " 5: 6267.3007365465164,\n",
       " 6: 46.226155042648315,\n",
       " 7: 416.19642186164856,\n",
       " 8: 211.02203834056854,\n",
       " 9: 639.97671222686768,\n",
       " 10: 165.11182737350464,\n",
       " 11: 542.30237913131714,\n",
       " 12: 225.15578699111938}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 547,\n",
       " 2: 149,\n",
       " 3: 3098,\n",
       " 4: 2473,\n",
       " 5: 3358,\n",
       " 6: 44,\n",
       " 7: 404,\n",
       " 8: 281,\n",
       " 9: 493,\n",
       " 10: 90,\n",
       " 11: 535,\n",
       " 12: 76}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~ms8909/10.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly\n",
    "from plotly import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "plotly.tools.set_credentials_file(username='ms8909', api_key='OOQ413hzFuXQFdeEbpJK')\n",
    "\n",
    "x_temp = []\n",
    "for i in range(len(dic_f.values())):\n",
    "    x_temp.append(i)\n",
    "data = []\n",
    "trace1 = go.Scatter(\n",
    "        x=['jan', 'feb', 'mar', 'apr', 'may','june', 'july', 'aug', 'sep', 'oct', 'nov', 'dec'],\n",
    "        y=dic_f.values(),\n",
    "        mode='lines',\n",
    "        name='UnitsShipped Forecast'\n",
    "        )\n",
    "data.append(trace1)\n",
    "\n",
    "trace2 = go.Scatter(\n",
    "            x=['jan', 'feb', 'mar', 'apr', 'may','june', 'july', 'aug', 'sep', 'oct', 'nov', 'dec'],\n",
    "            y=dic_r.values(),\n",
    "            mode='lines',\n",
    "            name='UnitsShipped Actual'\n",
    "        )\n",
    "\n",
    "data.append(trace2)\n",
    "\n",
    "fig = dict(data=data)\n",
    "py.iplot(fig, filename='line-mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p27)",
   "language": "python",
   "name": "conda_tensorflow_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
